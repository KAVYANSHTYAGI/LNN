{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a3c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     27\u001b[0m transform \u001b[38;5;241m=\u001b[39m Compose([\n\u001b[1;32m     28\u001b[0m     NormalizeTimestamps(),\n\u001b[1;32m     29\u001b[0m     RandomTemporalCrop(\u001b[38;5;241m0.8\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     ToBinnedTensor(encoder\u001b[38;5;241m=\u001b[39mspike_encoder)\n\u001b[1;32m     34\u001b[0m ])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --- DataLoaders ---\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_trial_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIN_MEMORY\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# --- Model, Loss, Optimizer, Scheduler ---\u001b[39;00m\n\u001b[1;32m     46\u001b[0m model \u001b[38;5;241m=\u001b[39m LiquidSpikeFormer(\n\u001b[1;32m     47\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mspike_encoder\u001b[38;5;241m.\u001b[39mnum_bins,\n\u001b[1;32m     48\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     58\u001b[0m )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "File \u001b[0;32m/mnt/m2ssd/research project/SNN/dataset.py:88\u001b[0m, in \u001b[0;36mget_trial_dataloaders\u001b[0;34m(root_dir, transform, batch_size, num_workers, pin_memory)\u001b[0m\n\u001b[1;32m     86\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m GestureTrialDataset(train_loader\u001b[38;5;241m.\u001b[39mget_samples(), transform)\n\u001b[1;32m     87\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m GestureTrialDataset(test_loader\u001b[38;5;241m.\u001b[39mget_samples(), transform)\n\u001b[0;32m---> 88\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m DataLoader(test_ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     92\u001b[0m                      num_workers\u001b[38;5;241m=\u001b[39mnum_workers, pin_memory\u001b[38;5;241m=\u001b[39mpin_memory,\n\u001b[1;32m     93\u001b[0m                      collate_fn\u001b[38;5;241m=\u001b[39mdefault_collate)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_dl, test_dl\n",
      "File \u001b[0;32m/mnt/m2ssd/research project/SNN/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:351\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/m2ssd/research project/SNN/.venv/lib/python3.8/site-packages/torch/utils/data/sampler.py:144\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import get_trial_dataloaders\n",
    "from model import LiquidSpikeFormer\n",
    "from loss import HybridSpikingLoss\n",
    "from optimizer import get_optimizer, get_scheduler\n",
    "from augmentation import Compose, NormalizeTimestamps, RandomTemporalCrop, RandomSpatialJitter, RandomPolarityFlip, AddEventNoise, ToBinnedTensor\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT_DIR = \"/mnt/m2ssd/research project/SNN/dataset/DVS  Gesture dataset/DvsGesture\"  # Path to DVS Gesture root\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "NUM_EPOCHS = 90\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Transforms ---\n",
    "spike_encoder = ...  # e.g., SpikeEncoder(num_bins=256, height=128, width=128)\n",
    "transform = Compose([\n",
    "    NormalizeTimestamps(),\n",
    "    RandomTemporalCrop(0.8),\n",
    "    RandomSpatialJitter(max_jitter=1, height=128, width=128),\n",
    "    RandomPolarityFlip(flip_prob=0.05),\n",
    "    AddEventNoise(spatial_sigma=0.5, temporal_sigma=0.01, height=128, width=128),\n",
    "    ToBinnedTensor(encoder=spike_encoder)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader, test_loader = get_trial_dataloaders(\n",
    "    root_dir=ROOT_DIR,\n",
    "    transform=transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "# --- Model, Loss, Optimizer, Scheduler ---\n",
    "model = LiquidSpikeFormer(\n",
    "    in_channels=spike_encoder.num_bins,\n",
    "    embed_dim=128,\n",
    "    nhead=4,\n",
    "    num_classes=11,\n",
    "    encoder_bins=spike_encoder.num_bins,\n",
    "    height=128,\n",
    "    width=128,\n",
    "    poisson=False,\n",
    "    learnable_bins=False,\n",
    "    smooth_kernel_size=5,\n",
    "    dropout=0.1\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = HybridSpikingLoss(lambda_s=1.0, lambda_m=0.5, lambda_t=0.5, lambda_a=0.1,\n",
    "                              target_sparsity=0.1, threshold=0.5)\n",
    "optimizer = get_optimizer(model, optimizer_name='AdamW', lr=LEARNING_RATE,\n",
    "                          weight_decay=WEIGHT_DECAY)\n",
    "scheduler = get_scheduler(optimizer,\n",
    "                          scheduler_name='WarmupCosine',\n",
    "                          total_steps=len(train_loader)*NUM_EPOCHS,\n",
    "                          warmup_steps=500)\n",
    "\n",
    "# --- Training & Evaluation Loop ---\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        events = batch['events'].to(DEVICE)\n",
    "        labels = batch['label'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(events)\n",
    "        loss = criterion(\n",
    "            out['logits'], labels,\n",
    "            spikes=out['spikes'],\n",
    "            membrane=out['membrane'],\n",
    "            threshold_param=out['threshold']\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * events.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            events = batch['events'].to(DEVICE)\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "            out = model(events)\n",
    "            loss = criterion(out['logits'], labels)\n",
    "            test_loss += loss.item() * events.size(0)\n",
    "\n",
    "            preds = out['logits'].argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = test_loss / total\n",
    "    test_acc = 100.0 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} \"\n",
    "          f\"Train Loss: {epoch_loss:.4f} \"\n",
    "          f\"Test Loss: {test_loss:.4f} \"\n",
    "          f\"Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"best_model_epoch{epoch}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'best_acc': best_acc\n",
    "        }, ckpt_path)\n",
    "        print(f\"Saved new best checkpoint to {ckpt_path}\")\n",
    "\n",
    "print(f\"Training complete. Best Acc: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bd5095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['errata.txt', 'gesture_mapping.csv', 'LICENSE.txt', 'README.txt', 'trials_to_test.txt', 'trials_to_train.txt', 'user01_fluorescent.aedat', 'user01_fluorescent_labels.csv', 'user01_fluorescent_led.aedat', 'user01_fluorescent_led_labels.csv', 'user01_lab.aedat', 'user01_lab_labels.csv', 'user01_led.aedat', 'user01_led_labels.csv', 'user01_natural.aedat', 'user01_natural_labels.csv', 'user02_fluorescent.aedat', 'user02_fluorescent_labels.csv', 'user02_fluorescent_led.aedat', 'user02_fluorescent_led_labels.csv', 'user02_lab.aedat', 'user11_natural_labels.csv', 'user12_fluorescent_led.aedat', 'user12_fluorescent_led_labels.csv', 'user12_led.aedat', 'user12_led_labels.csv', 'user13_fluorescent.aedat', 'user13_fluorescent_labels.csv', 'user13_fluorescent_led.aedat', 'user13_fluorescent_led_labels.csv', 'user13_lab.aedat', 'user13_lab_labels.csv', 'user13_led.aedat', 'user13_led_labels.csv', 'user13_natural.aedat', 'user14_fluorescent.aedat', 'user14_fluorescent_labels.csv', 'user14_fluorescent_led.aedat', 'user14_fluorescent_led_labels.csv', 'user14_led.aedat', 'user14_led_labels.csv', 'user14_natural.aedat', 'user14_natural_labels.csv', 'user15_fluorescent.aedat', 'user15_fluorescent_labels.csv', 'user15_fluorescent_led.aedat', 'user15_fluorescent_led_labels.csv', 'user15_lab.aedat', 'user15_lab_labels.csv', 'user15_led_labels.csv', 'user15_natural.aedat', 'user15_natural_labels.csv', 'user16_fluorescent.aedat', 'user16_fluorescent_labels.csv', 'user16_lab.aedat', 'user16_lab_labels.csv', 'user16_led.aedat', 'user16_led_labels.csv', 'user16_natural.aedat', 'user16_natural_labels.csv', 'user17_fluorescent.aedat', 'user17_fluorescent_labels.csv', 'user17_fluorescent_led.aedat', 'user17_fluorescent_led_labels.csv', 'user02_lab_labels.csv', 'user04_fluorescent_led.aedat', 'user05_natural_labels.csv', 'user07_lab.aedat', 'user09_lab.aedat', 'user11_natural.aedat', 'user13_natural_labels.csv', 'user15_led.aedat', 'user17_lab.aedat', 'user19_fluorescent_led.aedat', 'user21_fluorescent_labels.csv', 'user22_natural.aedat', 'user24_led_labels.csv', 'user27_fluorescent.aedat', 'user17_lab_labels.csv', 'user17_led.aedat', 'user17_led_labels.csv', 'user17_natural.aedat', 'user17_natural_labels.csv', 'user18_fluorescent.aedat', 'user18_fluorescent_labels.csv', 'user18_fluorescent_led.aedat', 'user18_fluorescent_led_labels.csv', 'user18_lab.aedat', 'user18_lab_labels.csv', 'user18_led.aedat', 'user18_led_labels.csv', 'user19_fluorescent.aedat', 'user19_fluorescent_labels.csv', 'user19_fluorescent_led_labels.csv', 'user19_lab.aedat', 'user19_lab_labels.csv', 'user19_led.aedat', 'user19_led_labels.csv', 'user19_natural.aedat', 'user19_natural_labels.csv', 'user20_fluorescent.aedat', 'user20_fluorescent_labels.csv', 'user20_fluorescent_led.aedat', 'user20_fluorescent_led_labels.csv', 'user20_led.aedat', 'user20_led_labels.csv', 'user21_fluorescent.aedat', 'user21_fluorescent_led.aedat', 'user21_fluorescent_led_labels.csv', 'user21_lab.aedat', 'user21_lab_labels.csv', 'user21_natural.aedat', 'user21_natural_labels.csv', 'user22_fluorescent.aedat', 'user22_fluorescent_labels.csv', 'user22_fluorescent_led.aedat', 'user22_fluorescent_led_labels.csv', 'user22_lab.aedat', 'user22_lab_labels.csv', 'user22_led.aedat', 'user22_led_labels.csv', 'user22_natural_labels.csv', 'user23_fluorescent.aedat', 'user23_fluorescent_labels.csv', 'user23_fluorescent_led.aedat', 'user23_fluorescent_led_labels.csv', 'user23_lab.aedat', 'user23_lab_labels.csv', 'user23_led.aedat', 'user23_led_labels.csv', 'user24_fluorescent.aedat', 'user24_fluorescent_labels.csv', 'user24_fluorescent_led.aedat', 'user24_fluorescent_led_labels.csv', 'user24_led.aedat', 'user25_fluorescent.aedat', 'user25_fluorescent_labels.csv', 'user25_led.aedat', 'user25_led_labels.csv', 'user26_fluorescent.aedat', 'user26_fluorescent_labels.csv', 'user26_fluorescent_led.aedat', 'user26_fluorescent_led_labels.csv', 'user26_lab.aedat', 'user26_lab_labels.csv', 'user26_led.aedat', 'user26_led_labels.csv', 'user26_natural.aedat', 'user26_natural_labels.csv', 'user27_fluorescent_labels.csv', 'user27_fluorescent_led.aedat', 'user27_fluorescent_led_labels.csv', 'user27_led.aedat', 'user27_led_labels.csv', 'user27_natural.aedat', 'user27_natural_labels.csv', 'user28_fluorescent.aedat', 'user28_fluorescent_labels.csv', 'user28_fluorescent_led.aedat', 'user28_fluorescent_led_labels.csv', 'user28_lab.aedat', 'user28_lab_labels.csv', 'user28_led.aedat', 'user28_led_labels.csv', 'user28_natural.aedat', 'user28_natural_labels.csv', 'user29_fluorescent.aedat', 'user29_fluorescent_labels.csv', 'user29_fluorescent_led.aedat', 'user29_fluorescent_led_labels.csv', 'user29_lab.aedat', 'user29_lab_labels.csv', 'user29_led.aedat', 'user29_led_labels.csv', 'user29_natural.aedat', 'user29_natural_labels.csv', 'user02_led.aedat', 'user02_led_labels.csv', 'user02_natural.aedat', 'user02_natural_labels.csv', 'user03_fluorescent.aedat', 'user03_fluorescent_labels.csv', 'user03_fluorescent_led.aedat', 'user03_fluorescent_led_labels.csv', 'user03_led.aedat', 'user03_led_labels.csv', 'user03_natural.aedat', 'user03_natural_labels.csv', 'user04_fluorescent.aedat', 'user04_fluorescent_labels.csv', 'user04_fluorescent_led_labels.csv', 'user04_led.aedat', 'user04_led_labels.csv', 'user04_natural.aedat', 'user04_natural_labels.csv', 'user05_fluorescent.aedat', 'user05_fluorescent_labels.csv', 'user05_fluorescent_led.aedat', 'user05_fluorescent_led_labels.csv', 'user05_lab.aedat', 'user05_lab_labels.csv', 'user05_led.aedat', 'user05_led_labels.csv', 'user05_natural.aedat', 'user06_fluorescent.aedat', 'user06_fluorescent_labels.csv', 'user06_fluorescent_led.aedat', 'user06_fluorescent_led_labels.csv', 'user06_lab.aedat', 'user06_lab_labels.csv', 'user06_led.aedat', 'user06_led_labels.csv', 'user06_natural.aedat', 'user06_natural_labels.csv', 'user07_fluorescent.aedat', 'user07_fluorescent_labels.csv', 'user07_fluorescent_led.aedat', 'user07_fluorescent_led_labels.csv', 'user07_lab_labels.csv', 'user07_led.aedat', 'user07_led_labels.csv', 'user08_fluorescent.aedat', 'user08_fluorescent_labels.csv', 'user08_fluorescent_led.aedat', 'user08_fluorescent_led_labels.csv', 'user08_lab.aedat', 'user08_lab_labels.csv', 'user08_led.aedat', 'user08_led_labels.csv', 'user09_fluorescent.aedat', 'user09_fluorescent_labels.csv', 'user09_fluorescent_led.aedat', 'user09_fluorescent_led_labels.csv', 'user09_lab_labels.csv', 'user09_led.aedat', 'user09_led_labels.csv', 'user09_natural.aedat', 'user09_natural_labels.csv', 'user10_fluorescent.aedat', 'user10_fluorescent_labels.csv', 'user10_fluorescent_led.aedat', 'user10_fluorescent_led_labels.csv', 'user10_lab.aedat', 'user10_lab_labels.csv', 'user10_led.aedat', 'user10_led_labels.csv', 'user11_fluorescent.aedat', 'user11_fluorescent_labels.csv', 'user11_fluorescent_led.aedat', 'user11_fluorescent_led_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"/mnt/m2ssd/research project/SNN/dataset/DVS  Gesture dataset/DvsGesture\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90014a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/mnt/m2ssd/research project/SNN/dataset/DVS  Gesture dataset/DvsGesture/gesture_mapping.csv\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c59952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'startTime_usec', 'endTime_usec']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/mnt/m2ssd/research project/SNN/dataset/DVS  Gesture dataset/DvsGesture/user01_lab_labels.csv\")\n",
    "print(df.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
